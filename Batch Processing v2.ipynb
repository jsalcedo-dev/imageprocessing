{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e37d9b",
   "metadata": {},
   "source": [
    "# Batch Processing Example\n",
    "In this example, we use the `micasense.imageset` class to load a set of directories of images into a list of `micasense.capture` objects, and we iterate over that list, saving out each image as an aligned stack of images as separate bands in a single tiff file each. Part of this process (via `imageutils.write_exif_to_stack`) injects that the GPS, capture datetime, camera model, etc into the processed images, allowing us to stitch those images using commercial software such as Pix4DMapper or Agisoft Metashape.\n",
    "\n",
    "Note: for this example to work, the images must have a valid RigRelatives tag. This requires RedEdge (3/M/MX) version of at least 3.4.0, or any version of RedEdge-P/Altum-PT/Altum/RedEdge-MX Dual. If your images don't meet that spec, you can also follow this support article to add the RigRelatives tag to your imagery: https://support.micasense.com/hc/en-us/articles/360006368574-Modifying-older-collections-for-Pix4Dfields-support"
   ]
  },
  {
   "cell_type": "code",
   "id": "c64ead96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T17:19:37.456497Z",
     "start_time": "2025-09-10T17:19:37.338551Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "80646655",
   "metadata": {},
   "source": [
    "# Load Images into ImageSet\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2081b06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T17:19:47.536285Z",
     "start_time": "2025-09-10T17:19:37.458102Z"
    }
   },
   "source": [
    "from ipywidgets import FloatProgress, Layout\n",
    "from IPython.display import display\n",
    "import micasense.imageset as imageset\n",
    "import micasense.capture as capture\n",
    "import os, glob\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "exiftool_dir = r\"C:\\exiftool\\exiftool.exe\"\n",
    "if os.name == 'nt': # Check if the OS is Windows\n",
    "    os.environ['PATH'] = exiftool_dir + os.pathsep + os.environ['PATH']\n",
    "\n",
    "# set to True if you have an Altum-PT\n",
    "# or RedEdge-P and wish to output pan-sharpened stacks \n",
    "panSharpen = True \n",
    "\n",
    "# If creating a lot of stacks, it is more efficient to save the metadata\n",
    "# and then write all of the exif to the images after the stacks are created\n",
    "write_exif_to_individual_stacks = False\n",
    "\n",
    "panelNames = None\n",
    "useDLS = True\n",
    "\n",
    "# set your image path here. See more here: https://docs.python.org/3/library/pathlib.html\n",
    "imagePath = Path(r\"F:\\Users\\jsalc\\Documents\\Supherb Drone Images Raw\\88-21 Merced 9-9-25\\0002SET\\000\")\n",
    "folder_name = Path(r\"F:\\Users\\jsalc\\Documents\\Supherb Drone Images Raw\\88-21 Merced 9-9-25\\0002SET\\000\")\n",
    "imagePathPanel = Path(r\"F:\\Users\\jsalc\\Documents\\Supherb Drone Images Raw\\88-21 Merced 9-9-25\\0000SET\\000\")\n",
    "\n",
    "# these will return lists of image paths as strings. Comment out of you aren't using panels. \n",
    "panelNames = list(imagePathPanel.glob('IMG_0001_*.tif'))\n",
    "panelNames = [x.as_posix() for x in panelNames]\n",
    "\n",
    "\n",
    "if panelNames:\n",
    "    panelCap = capture.Capture.from_filelist(panelNames)\n",
    "else:\n",
    "    panelCap = None\n",
    "    \n",
    "\n",
    "# destinations on your computer to put the stacks\n",
    "# and RGB thumbnails\n",
    "outputPath = imagePath  / 'stacks'\n",
    "thumbnailPath = outputPath / 'thumbnails'\n",
    "\n",
    "if panelCap:\n",
    "    cam_model = panelCap.camera_model\n",
    "    cam_serial = panelCap.camera_serial\n",
    "\n",
    "# determine if this sensor has a panchromatic band \n",
    "if cam_model == 'RedEdge-P' or cam_model == 'Altum-PT':\n",
    "    panchroCam = True\n",
    "else:\n",
    "    panchroCam = False\n",
    "    panSharpen = False \n",
    "# panchroCam=True\n",
    "    \n",
    "# if this is a multicamera system like the RedEdge-MX Dual,\n",
    "# we can combine the two serial numbers to help identify \n",
    "# this camera system later. \n",
    "if len(panelCap.camera_serials) > 1:\n",
    "    cam_serial = \"_\".join(panelCap.camera_serials)\n",
    "    print(\"Serial number:\",cam_serial)\n",
    "else:\n",
    "    cam_serial = panelCap.camera_serial\n",
    "    print(\"Serial number:\",cam_serial)\n",
    "    \n",
    "overwrite = False # can be set to set to False to continue interrupted processing\n",
    "generateThumbnails = True\n",
    "\n",
    "# Allow this code to align both radiance and reflectance images; but excluding\n",
    "# a definition for panelNames above, radiance images will be used\n",
    "# For panel images, efforts will be made to automatically extract the panel information\n",
    "# but if the panel/firmware is before Altum 1.3.5, RedEdge 5.1.7 the panel reflectance\n",
    "# will need to be set in the panel_reflectance_by_band variable.\n",
    "# Note: radiance images will not be used to properly create NDVI/NDRE images below.\n",
    "if panelNames is not None:\n",
    "    panelCap = capture.Capture.from_filelist(panelNames)\n",
    "else:\n",
    "    panelCap = None\n",
    "\n",
    "if panelCap is not None:\n",
    "    if panelCap.panel_albedo() is not None and not any(v is None for v in panelCap.panel_albedo()):\n",
    "        panel_reflectance_by_band = panelCap.panel_albedo()\n",
    "    else:\n",
    "        panel_reflectance_by_band = [0.49]*len(panelCap.eo_band_names()) #RedEdge band_index order\n",
    "    \n",
    "    panel_irradiance = panelCap.panel_irradiance(panel_reflectance_by_band)    \n",
    "    img_type = \"reflectance\"\n",
    "else:\n",
    "    if useDLS:\n",
    "        img_type='reflectance'\n",
    "    else:\n",
    "        img_type = \"radiance\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial number: PR03-2310192-MS\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "60736009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T17:19:47.927545Z",
     "start_time": "2025-09-10T17:19:47.537863Z"
    }
   },
   "source": [
    "## This progress widget is used for display of the long-running process\n",
    "f = FloatProgress(min=0, max=1, layout=Layout(width='100%'), description=\"Loading\")\n",
    "display(f)\n",
    "def update_f(val):\n",
    "    if (val - f.value) > 0.005 or val == 1: #reduces cpu usage from updating the progressbar by 10x\n",
    "        f.value=val\n",
    "\n",
    "imgset = imageset.ImageSet.from_directory(imagePath, progress_callback=update_f)\n",
    "update_f(1.0)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, description='Loading', layout=Layout(width='100%'), max=1.0)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a73092765fb4e3282c643ed03143584"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "6c0a234d",
   "metadata": {},
   "source": [
    "# Capture map\n",
    "We can map out the capture GPS locations to ensure we are processing the right data. A GeoJSON of the captures will later be saved to the outputPath."
   ]
  },
  {
   "cell_type": "code",
   "id": "9e9c437c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T17:19:48.066816Z",
     "start_time": "2025-09-10T17:19:47.930796Z"
    }
   },
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from mapboxgl.viz import *\n",
    "from mapboxgl.utils import df_to_geojson, create_radius_stops, scale_between\n",
    "from mapboxgl.utils import create_color_stops\n",
    "import pandas as pd\n",
    "\n",
    "data, columns = imgset.as_nested_lists()\n",
    "df = pd.DataFrame.from_records(data, index='timestamp', columns=columns)\n",
    "\n",
    "#Insert your mapbox token here\n",
    "token = 'pk.eyJ1Ijoic2VudGlsbGlhbmFseXRpY3MiLCJhIjoiY204aTJsa3Z4MDk1YTJxb241dzdpeXd2ZSJ9.J-EmczpBD5bvvI8NiVG8kQ'\n",
    "color_property = 'dls-yaw'\n",
    "num_color_classes = 8\n",
    "\n",
    "min_val = df[color_property].min()\n",
    "max_val = df[color_property].max()\n",
    "\n",
    "import jenkspy\n",
    "from jenkspy import JenksNaturalBreaks\n",
    "geojson_data = df_to_geojson(df,columns[3:],lat='latitude',lon='longitude')\n",
    "jnb = JenksNaturalBreaks(num_color_classes)\n",
    "jnb.fit(df[color_property])\n",
    "breaks = jnb.breaks_\n",
    "color_stops = create_color_stops(breaks,colors='YlOrRd')\n",
    "\n",
    "viz = CircleViz(geojson_data, access_token=token, color_property=color_property,\n",
    "                color_stops=color_stops,\n",
    "                center=[df['longitude'].median(),df['latitude'].median()], \n",
    "                zoom=16, height='600px',\n",
    "                style='mapbox://styles/mapbox/satellite-streets-v9')\n",
    "viz.show()"
   ],
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmapboxgl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_color_stops\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m data, columns \u001B[38;5;241m=\u001B[39m \u001B[43mimgset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_nested_lists\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_records(data, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m, columns\u001B[38;5;241m=\u001B[39mcolumns)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#Insert your mapbox token here\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\imageprocessing\\micasense\\imageset.py:109\u001B[0m, in \u001B[0;36mImageSet.as_nested_lists\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;124;03mGet timestamp, latitude, longitude, altitude, capture_id, dls-yaw, dls-pitch, dls-roll, and irradiance from all\u001B[39;00m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03mCaptures.\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m:return: List data from all Captures, List column headers.\u001B[39;00m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    103\u001B[0m columns \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maltitude\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapture_id\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdls-yaw\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdls-pitch\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdls-roll\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    108\u001B[0m ]\n\u001B[1;32m--> 109\u001B[0m irr \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mirr-\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(wve) \u001B[38;5;28;01mfor\u001B[39;00m wve \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptures\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mcenter_wavelengths()]\n\u001B[0;32m    110\u001B[0m columns \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m irr\n\u001B[0;32m    111\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "e540a655",
   "metadata": {},
   "source": [
    "# Define which warp method to use\n",
    "For newer data sets with RigRelatives tags (images captured with RedEdge (3/M/MX) version 3.4.0 or greater with a valid calibration load, see https://support.micasense.com/hc/en-us/articles/360005428953-Updating-RedEdge-for-Pix4Dfields), we can use the RigRelatives for a simple alignment. To use this simple alignment, simply set `warp_matrices=None` \n",
    "\n",
    "For sets without those tags, or sets that require a RigRelatives optimization, we can go through the Alignment.ipynb notebook and get a set of warp_matrices that we can use here to align."
   ]
  },
  {
   "cell_type": "code",
   "id": "635ad8d8",
   "metadata": {},
   "source": [
    "from numpy import array\n",
    "from numpy import float32\n",
    "from skimage.transform import ProjectiveTransform\n",
    "\n",
    "if panchroCam:\n",
    "    warp_matrices_filename = cam_serial + \"_warp_matrices_SIFT.npy\"\n",
    "else:\n",
    "    warp_matrices_filename = cam_serial + \"_warp_matrices_opencv.npy\"\n",
    "\n",
    "if Path('./' + warp_matrices_filename).is_file():\n",
    "    print(\"Found existing warp matrices for camera\", cam_serial)\n",
    "    load_warp_matrices = np.load(warp_matrices_filename, allow_pickle=True)\n",
    "    loaded_warp_matrices = []\n",
    "    for matrix in load_warp_matrices: \n",
    "        if panchroCam:\n",
    "            transform = ProjectiveTransform(matrix=matrix.astype('float64'))\n",
    "            loaded_warp_matrices.append(transform)\n",
    "        else:\n",
    "            loaded_warp_matrices.append(matrix.astype('float32'))\n",
    "\n",
    "    if panchroCam:\n",
    "        warp_matrices_SIFT = loaded_warp_matrices\n",
    "    else:\n",
    "        warp_matrices = loaded_warp_matrices\n",
    "    print(\"Loaded warp matrices from\",Path('./' + warp_matrices_filename).resolve())\n",
    "else:\n",
    "    print(\"No warp matrices found at expected location:\",warp_matrices_filename)\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from osgeo import gdal\n",
    "import os, sys\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"GDAL version:\", gdal.__version__)\n",
    "\n",
    "# Make sure drivers are registered\n",
    "gdal.AllRegister()\n",
    "drv = gdal.GetDriverByName(\"GTiff\")\n",
    "print(\"GTiff driver:\", \"OK\" if drv else \"NOT FOUND\")"
   ],
   "id": "147e200364a1bab9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3aae7f09",
   "metadata": {},
   "source": [
    "## Align images and save each capture to a layered TIFF file"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdc195da",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import exiftool\n",
    "import datetime\n",
    "import micasense.imageutils as imageutils\n",
    "import re\n",
    "exif_list = []\n",
    "## This progress widget is used for display of the long-running process\n",
    "f2 = FloatProgress(min=0, max=1, layout=Layout(width='100%'), description=\"Saving\")\n",
    "display(f2)\n",
    "def update_f2(val):\n",
    "    f2.value=val\n",
    "\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "if generateThumbnails and not os.path.exists(thumbnailPath):\n",
    "    os.makedirs(thumbnailPath)\n",
    "\n",
    "# Save out geojson data so we can open the image capture locations in our GIS\n",
    "with open(os.path.join(outputPath,'imageSet.json'),'w') as f:\n",
    "    f.write(str(geojson_data))\n",
    "    \n",
    "try:\n",
    "    irradiance = panel_irradiance+[0]\n",
    "except NameError:\n",
    "    irradiance = None\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for i,capture in enumerate(imgset.captures):\n",
    "    try:  \n",
    "        path_parts = folder_name.split(os.sep)\n",
    "        # Extract the desired folder names from the path.\n",
    "        # We are getting the fourth-to-last item (the field name)\n",
    "        # and the last item (the set number).\n",
    "        field_name = path_parts[-4]\n",
    "        trial_name = path_parts[-3]\n",
    "        set_number = path_parts[-2]\n",
    "        \n",
    "        # Clean up the folder names to be safe for filenames.\n",
    "        # This replaces spaces, backslashes, and other non-alphanumeric\n",
    "        # characters with underscores.\n",
    "        clean_field_name = re.sub(r'[^a-zA-Z0-9]', '_', field_name)\n",
    "        clean_set_number = re.sub(r'[^a-zA-Z0-9]', '_', set_number)\n",
    "        clean_trial_name = re.sub(r'[^a-zA-Z0-9]', '_', trial_name)\n",
    "    \n",
    "        \n",
    "        outputFilename = f\"{clean_field_name}_{clean_set_number}_{str(i).zfill(4)}_{capture.uuid}.tif\"\n",
    "        thumbnailFilename = f\"{clean_field_name}_{clean_set_number}_{str(i).zfill(4)}_{capture.uuid}.jpg\"\n",
    "        fullOutputPath = os.path.join(outputPath, outputFilename)\n",
    "        fullThumbnailPath= os.path.join(thumbnailPath, thumbnailFilename)\n",
    "        if (not os.path.exists(fullOutputPath)) or overwrite:\n",
    "            if(len(capture.images) == len(imgset.captures[0].images)):\n",
    "                if panchroCam:\n",
    "                    capture.radiometric_pan_sharpened_aligned_capture(\n",
    "                        warp_matrices=warp_matrices_SIFT,\n",
    "                        irradiance_list=capture.dls_irradiance(),   # correct method name\n",
    "                        img_type=img_type                           # 'radiance' or 'reflectance'\n",
    "                    )\n",
    "                else:\n",
    "                    capture.create_aligned_capture(irradiance_list=irradiance, warp_matrices=warp_matrices)\n",
    "                exif_list.append(imageutils.prepare_exif_for_stacks(capture,fullOutputPath))\n",
    "                capture.save_capture_as_stack(fullOutputPath, pansharpen=panSharpen,sort_by_wavelength=True, write_exif=write_exif_to_individual_stacks)\n",
    "                if generateThumbnails:\n",
    "                    capture.save_capture_as_rgb(fullThumbnailPath)\n",
    "        capture.clear_image_data()\n",
    "        update_f2(float(i)/float(len(imgset.captures)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "update_f2(1.0)\n",
    "end = datetime.datetime.now()\n",
    "\n",
    "print(\"Saving time: {}\".format(end-start))\n",
    "print(\"Alignment+Saving rate: {:.2f} images per second\".format(float(len(imgset.captures))/float((end-start).total_seconds())))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "19995c8d4638218b"
  },
  {
   "cell_type": "markdown",
   "id": "f4b88c80",
   "metadata": {},
   "source": [
    "# Write EXIF data to stacks\n",
    "As mentioned above, it is more time intensive to write the exif data to each image as it is created. Here, we write the exif data after all of the TIFF files have been created. This should take a few seconds per stack."
   ]
  },
  {
   "cell_type": "code",
   "id": "fac88b6a",
   "metadata": {},
   "source": [
    "\n",
    "if write_exif_to_individual_stacks == False:\n",
    "    start = datetime.datetime.now()\n",
    "    for exif in exif_list:\n",
    "        imageutils.write_exif_to_stack(existing_exif_list=exif)\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"Saving time: {}\".format(end-start))\n",
    "    print(\"Alignment+Saving rate: {:.2f} images per second\".format(float(len(exif_list))/float((end-start).total_seconds())))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea464070",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:micasense] *",
   "language": "python",
   "name": "conda-env-micasense-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
